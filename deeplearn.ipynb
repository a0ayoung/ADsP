{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAU\\Anaconda3\\envs\\mlbook\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy 1.1.0\n",
      "numpy 1.14.3\n",
      "matplotlib 2.2.2\n",
      "pandas 0.23.0\n",
      "sklearn 0.19.1\n",
      "h5py 2.7.1\n",
      "theano 1.0.2\n",
      "keras 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import pydotplus\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print('scipy ' + scipy.__version__)\n",
    "print('numpy ' + np.__version__)\n",
    "print('matplotlib ' + matplotlib.__version__)\n",
    "print('pandas ' + pd.__version__)\n",
    "print('sklearn ' + sklearn.__version__)\n",
    "print('h5py ' + h5py.__version__)\n",
    "\n",
    "print('theano ' + theano.__version__)\n",
    "print('keras ' + keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split    \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data= pd.read_csv('senior_d_preprocessed_60by50.csv')\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_data=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data=scaling_data.fit_transform(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set=train_test_split(sample_data,test_size=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터셋 생성하기\n",
    "x_train = train_set.drop(['suicide'], axis=1).values  \n",
    "y_train = train_set['suicide'].values\n",
    "\n",
    "x_test = test_set.drop(['suicide'], axis=1).values  \n",
    "y_test = test_set['suicide'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_inputs = 32  \n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "he_init=tf.contrib.layers.variance_scaling_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7777/7777 [==============================] - 1s 77us/step - loss: 7.9722 - acc: 0.4999\n",
      "Epoch 2/2\n",
      "7777/7777 [==============================] - 0s 41us/step - loss: 7.9722 - acc: 0.4999\n",
      "## training loss and acc ##\n",
      "[7.972217800900181, 7.972217789127938]\n",
      "[0.49993570785649993, 0.49993570785649993]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "## evaluation loss and_metrics ##\n",
      "[1.192093321833454e-07, 1.0]\n",
      "## yhat ##\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "#model = Sequential()\n",
    "#model.add(Dense(32, activation='tanh'))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(PReLU())\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(20))\n",
    "#model.add(PReLU())\n",
    "\n",
    "#model.add(Dense(1))\n",
    "#model.add(Activation('softmax'))\n",
    "#model.add(Dense(32,activation='elu'))#입력\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(32,activation='elu'))#입력\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='elu', input_dim=32))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16,activation='elu'))#입력\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(8,activation='elu'))#입력\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(4,activation='elu'))#입력\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2,activation='elu'))#입력\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "#model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "tensorcallback= TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "hist = model.fit(x_train, y_train, epochs=2, batch_size=32, callbacks=[tensorcallback])\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "print('## training loss and acc ##')\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['acc'])\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "xhat = x_test[0:1]\n",
    "yhat = model.predict(xhat)\n",
    "print('## yhat ##')\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,769\n",
      "Trainable params: 1,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"C:/Users/KAU/Downloads/bigdummy_normalize.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:-1].astype(float)\n",
    "Y = dataset[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAU\\Anaconda3\\envs\\mlbook\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\KAU\\Anaconda3\\envs\\mlbook\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(32, input_dim=32, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 5s 753us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 334us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 328us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 341us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 3s 358us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 329us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 328us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 337us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 3s 366us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 331us/step - loss: 8.0590 - acc: 0.5000\n",
      "778/778 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 6s 797us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 355us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 355us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 356us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 347us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 355us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 336us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 332us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 333us/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 331us/step - loss: 8.0590 - acc: 0.5000\n",
      "778/778 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 6s 793us/step - loss: 0.6703 - acc: 0.6061\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 337us/step - loss: 0.6382 - acc: 0.6376\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 336us/step - loss: 0.6384 - acc: 0.6401\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 334us/step - loss: 0.6334 - acc: 0.6456\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 333us/step - loss: 0.6400 - acc: 0.6406\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 337us/step - loss: 0.6401 - acc: 0.6394\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 349us/step - loss: 0.6300 - acc: 0.6467\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 352us/step - loss: 0.6325 - acc: 0.6469\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 336us/step - loss: 0.6298 - acc: 0.6450\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 337us/step - loss: 0.6319 - acc: 0.6411\n",
      "778/778 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 6s 802us/step - loss: 0.6664 - acc: 0.6056\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 340us/step - loss: 0.6412 - acc: 0.6347\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 342us/step - loss: 0.6360 - acc: 0.6399\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 338us/step - loss: 0.6358 - acc: 0.6414\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 344us/step - loss: 0.6354 - acc: 0.6416\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 339us/step - loss: 0.6312 - acc: 0.6467\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 346us/step - loss: 0.6354 - acc: 0.6441\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 349us/step - loss: 0.6324 - acc: 0.6480\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 350us/step - loss: 0.6310 - acc: 0.6529\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 340us/step - loss: 0.6320 - acc: 0.6490\n",
      "778/778 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 6s 811us/step - loss: 0.6821 - acc: 0.5979\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 356us/step - loss: 0.6387 - acc: 0.6377\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 344us/step - loss: 0.6354 - acc: 0.6390\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 342us/step - loss: 0.6363 - acc: 0.6429\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 341us/step - loss: 0.6338 - acc: 0.6401\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 339us/step - loss: 0.6336 - acc: 0.6383\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 344us/step - loss: 0.6360 - acc: 0.6477\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 341us/step - loss: 0.6311 - acc: 0.6456\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 356us/step - loss: 0.6301 - acc: 0.6444\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 339us/step - loss: 0.6265 - acc: 0.6487\n",
      "778/778 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 6s 811us/step - loss: 0.6883 - acc: 0.6047\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 3s 361us/step - loss: 0.6407 - acc: 0.6290\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 355us/step - loss: 0.6388 - acc: 0.6371\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 344us/step - loss: 0.6355 - acc: 0.6473\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 343us/step - loss: 0.6410 - acc: 0.6414\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 343us/step - loss: 0.6338 - acc: 0.6446\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 345us/step - loss: 0.6342 - acc: 0.6423\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 343us/step - loss: 0.6318 - acc: 0.6451\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 345us/step - loss: 0.6335 - acc: 0.6446\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 3s 361us/step - loss: 0.6303 - acc: 0.6483\n",
      "778/778 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 6s 818us/step - loss: 0.6672 - acc: 0.6083\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 348us/step - loss: 0.6434 - acc: 0.6360\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 3s 375us/step - loss: 0.6382 - acc: 0.6474\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 357us/step - loss: 0.6363 - acc: 0.6487\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 340us/step - loss: 0.6397 - acc: 0.6437\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 341us/step - loss: 0.6339 - acc: 0.6459\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 341us/step - loss: 0.6325 - acc: 0.6520\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 344us/step - loss: 0.6295 - acc: 0.6536\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 347us/step - loss: 0.6270 - acc: 0.6533\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 351us/step - loss: 0.6262 - acc: 0.6484\n",
      "778/778 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 6s 818us/step - loss: 0.6763 - acc: 0.6031\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 344us/step - loss: 0.6434 - acc: 0.6391\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 342us/step - loss: 0.6372 - acc: 0.6399\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 3s 363us/step - loss: 0.6413 - acc: 0.6451\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 3s 367us/step - loss: 0.6459 - acc: 0.6317\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 344us/step - loss: 0.6331 - acc: 0.6483\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 357us/step - loss: 0.6320 - acc: 0.6436\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 346us/step - loss: 0.6309 - acc: 0.6473\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 2s 343us/step - loss: 0.6306 - acc: 0.6480\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 340us/step - loss: 0.6293 - acc: 0.6473\n",
      "778/778 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 6s 806us/step - loss: 0.6718 - acc: 0.5971\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 3s 360us/step - loss: 0.6423 - acc: 0.6301\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 341us/step - loss: 0.6375 - acc: 0.6389\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 341us/step - loss: 0.6379 - acc: 0.6460\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 3s 369us/step - loss: 0.6394 - acc: 0.6403\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 356us/step - loss: 0.6311 - acc: 0.6426\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 341us/step - loss: 0.6301 - acc: 0.6480\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 340us/step - loss: 0.6336 - acc: 0.6467\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 343us/step - loss: 0.6280 - acc: 0.6524\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 339us/step - loss: 0.6276 - acc: 0.6449\n",
      "778/778 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "7002/7002 [==============================] - 6s 831us/step - loss: 0.8513 - acc: 0.5883\n",
      "Epoch 2/10\n",
      "7002/7002 [==============================] - 2s 347us/step - loss: 0.6449 - acc: 0.6278\n",
      "Epoch 3/10\n",
      "7002/7002 [==============================] - 2s 357us/step - loss: 0.6361 - acc: 0.6350\n",
      "Epoch 4/10\n",
      "7002/7002 [==============================] - 2s 346us/step - loss: 0.6387 - acc: 0.6408\n",
      "Epoch 5/10\n",
      "7002/7002 [==============================] - 2s 345us/step - loss: 0.6333 - acc: 0.6441\n",
      "Epoch 6/10\n",
      "7002/7002 [==============================] - 3s 379us/step - loss: 0.6323 - acc: 0.6487\n",
      "Epoch 7/10\n",
      "7002/7002 [==============================] - 2s 350us/step - loss: 0.6326 - acc: 0.6464\n",
      "Epoch 8/10\n",
      "7002/7002 [==============================] - 2s 350us/step - loss: 0.6326 - acc: 0.6440\n",
      "Epoch 9/10\n",
      "7002/7002 [==============================] - 2s 346us/step - loss: 0.6323 - acc: 0.6421\n",
      "Epoch 10/10\n",
      "7002/7002 [==============================] - 2s 352us/step - loss: 0.6330 - acc: 0.6454\n",
      "776/776 [==============================] - 2s 2ms/step\n",
      "Results: 61.80% (6.01%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=10, batch_size=5, verbose=1,r)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 65.26% (1.85%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=200, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dummy = pandas.read_csv(\"C:/Users/KAU/Downloads/try_1.csv\", header=None)\n",
    "##scale\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaling_data=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data=scaling_data.fit_transform(dummy)\n",
    "dataframe=pd.DataFrame(scaled_data)\n",
    "\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:-1].astype(float)\n",
    "Y = dataset[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAU\\Anaconda3\\envs\\mlbook\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\KAU\\Anaconda3\\envs\\mlbook\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(15, input_dim=15, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 62.53% (6.41%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with normalized\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 66.12% (2.72%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline model with nomalized +standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 65.45% (1.42%)\n"
     ]
    }
   ],
   "source": [
    "# smaller model\n",
    "def create_smaller():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(16, input_dim=32, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 60.27% (6.85%)\n"
     ]
    }
   ],
   "source": [
    "# larger model\n",
    "def create_larger():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(6, input_dim=32, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
